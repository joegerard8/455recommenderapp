{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PYTHON For Recommender Deployment Project ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "import joblib\n",
    "\n",
    "# Load the datasets\n",
    "articles_df = pd.read_csv('shared_articles.csv')\n",
    "interactions_df = pd.read_csv('users_interactions.csv')\n",
    "\n",
    "# Map the eventType to numerical ratings\n",
    "event_type_strength = {\n",
    "    'VIEW': 1,\n",
    "    'LIKE': 2, \n",
    "    'FOLLOW': 3,\n",
    "    'BOOKMARK': 4,\n",
    "    'COMMENT CREATED': 5\n",
    "}\n",
    "\n",
    "interactions_df['eventStrength'] = interactions_df['eventType'].apply(lambda x: event_type_strength[x])\n",
    "\n",
    "# Group by user and item to get the strongest interaction for each user-item pair\n",
    "grouped_interactions = interactions_df.groupby(['personId', 'contentId']).agg({'eventStrength': 'max'}).reset_index()\n",
    "\n",
    "# Create a user-item matrix\n",
    "user_item_matrix = grouped_interactions.pivot(index='personId', columns='contentId', values='eventStrength').fillna(0)\n",
    "joblib.dump(user_item_matrix, './backend/models/user_item_matrix.sav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Collaborative Filtering Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user_item_matrix.sav']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate user similarity matrix\n",
    "user_similarity = cosine_similarity(user_item_matrix)\n",
    "user_similarity_df = pd.DataFrame(user_similarity, index=user_item_matrix.index, columns=user_item_matrix.index)\n",
    "\n",
    "def get_cf_recommendations(user_id, user_item_matrix, user_similarity_df, n=5):\n",
    "    \"\"\"\n",
    "    Generate collaborative filtering recommendations for a given user\n",
    "    \"\"\"\n",
    "    # Get similarity scores for this user with all other users\n",
    "    if user_id not in user_similarity_df.index:\n",
    "        print(f\"User {user_id} not found in the dataset\")\n",
    "        return {}\n",
    "        \n",
    "    user_similarities = user_similarity_df.loc[user_id].drop(user_id)\n",
    "    \n",
    "    # Get items this user has interacted with\n",
    "    user_items = user_item_matrix.loc[user_id]\n",
    "    user_items = user_items[user_items > 0].index.tolist()\n",
    "    \n",
    "    # Find items that similar users have interacted with but this user hasn't\n",
    "    recommendations = {}\n",
    "    \n",
    "    for similar_user, similarity in user_similarities.items():\n",
    "        if similarity <= 0:  # Skip users with no similarity\n",
    "            continue\n",
    "        \n",
    "        similar_user_items = user_item_matrix.loc[similar_user]\n",
    "        similar_user_items = similar_user_items[similar_user_items > 0].index.tolist()\n",
    "        \n",
    "        # Get items this user hasn't interacted with\n",
    "        new_items = [item for item in similar_user_items if item not in user_items]\n",
    "        \n",
    "        for item in new_items:\n",
    "            if item in recommendations:\n",
    "                recommendations[item] += similarity\n",
    "            else:\n",
    "                recommendations[item] = similarity\n",
    "    \n",
    "    # Sort recommendations by score and return top n\n",
    "    recommendations = sorted(recommendations.items(), key=lambda x: x[1], reverse=True)[:n]\n",
    "    return {item_id: score for item_id, score in recommendations}\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(user_similarity_df, 'cf_model.sav')\n",
    "joblib.dump(user_item_matrix, 'user_item_matrix.sav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Content-Based Filtering Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['content_model.sav']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the content data\n",
    "articles_df['content'] = articles_df['title'] + ' ' + articles_df['text']\n",
    "\n",
    "# Create TF-IDF vectorizer\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(articles_df['content'])\n",
    "\n",
    "# Calculate item similarity matrix using cosine similarity\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "def get_content_recommendations(item_id, cosine_sim, articles_df, n=5):\n",
    "    \"\"\"\n",
    "    Generate content-based recommendations for a given item\n",
    "    \"\"\"\n",
    "    # Check if the item exists\n",
    "    if item_id not in articles_df['contentId'].values:\n",
    "        print(f\"Item {item_id} not found in the dataset\")\n",
    "        return {}\n",
    "    \n",
    "    # Get the index of the item in the dataframe\n",
    "    idx = articles_df[articles_df['contentId'] == item_id].index[0]\n",
    "    \n",
    "    # Get similarity scores for this item with all other items\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    \n",
    "    # Sort items based on similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get the top n most similar items (excluding the item itself)\n",
    "    sim_scores = sim_scores[1:n+1]\n",
    "    \n",
    "    # Get the item indices\n",
    "    item_indices = [i[0] for i in sim_scores]\n",
    "    \n",
    "    # Get the contentIds and similarity scores\n",
    "    recommendations = {}\n",
    "    for i, score in enumerate(sim_scores):\n",
    "        item_idx = item_indices[i]\n",
    "        item_id = articles_df.iloc[item_idx]['contentId']\n",
    "        recommendations[item_id] = score[1]\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(cosine_sim, 'content_model.sav')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
